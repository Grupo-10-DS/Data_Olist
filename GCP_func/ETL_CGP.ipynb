{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import mysql.connector\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"data_olist_csv\"\n",
    "MYSQL_USR = \"root\"\n",
    "MYSQL_PWD = \"\"\n",
    "MYSQL_HOST = \"34.135.162.156\"\n",
    "MYSQL_DB_NAME = \"Olist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def list_blobs_with_prefix(bucket_name, prefix, delimiter=None):\n",
    "    \"\"\"Lists all the blobs in the bucket that begin with the prefix.\n",
    "\n",
    "    This can be used to list all blobs in a \"folder\", e.g. \"public/\".\n",
    "\n",
    "    The delimiter argument can be used to restrict the results to only the\n",
    "    \"files\" in the given \"folder\". Without the delimiter, the entire tree under\n",
    "    the prefix is returned. For example, given these blobs:\n",
    "\n",
    "        a/1.txt\n",
    "        a/b/2.txt\n",
    "\n",
    "    If you specify prefix ='a/', without a delimiter, you'll get back:\n",
    "\n",
    "        a/1.txt\n",
    "        a/b/2.txt\n",
    "\n",
    "    However, if you specify prefix='a/' and delimiter='/', you'll get back\n",
    "    only the file directly under 'a/':\n",
    "\n",
    "        a/1.txt\n",
    "\n",
    "    As part of the response, you'll also get back a blobs.prefixes entity\n",
    "    that lists the \"subfolders\" under `a/`:\n",
    "\n",
    "        a/b/\n",
    "    \"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=delimiter)\n",
    "    \n",
    "    return [blob.name.replace(\"deltas_por_cargar/\",\"\") for blob in blobs][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_delta.csv', 'order_delta.csv', 'payment_delta.csv', 'review_delta.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_blobs = list_blobs_with_prefix(BUCKET_NAME,prefix=\"deltas_por_cargar/\")\n",
    "list_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_server_connection(host_name, user_name, user_password):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name, password=user_password, user=user_name\n",
    "        )\n",
    "        print(\"MySQL Database connection successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_db_connection(host_name, user_name, user_password, db_name):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name, user=user_name, passwd=user_password, database=db_name\n",
    "        )\n",
    "        print(\"MySQL Database connection successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(\"Query successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_delta = pd.read_csv(\"gs://data_olist_csv/deltas_por_cargar/item_delta.csv\")\n",
    "order_delta = pd.read_csv(\"gs://data_olist_csv/deltas_por_cargar/order_delta.csv\")\n",
    "payment_delta = pd.read_csv(\"gs://data_olist_csv/deltas_por_cargar/payment_delta.csv\")\n",
    "review_delta = pd.read_csv(\"gs://data_olist_csv/deltas_por_cargar/review_delta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "conf_mysql = {\n",
    "    \"host_name\": MYSQL_HOST,\n",
    "    \"user_name\": MYSQL_USR,\n",
    "    \"user_password\": MYSQL_PWD,\n",
    "    \"db_name\": MYSQL_DB_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "db_connection = create_db_connection(\n",
    "    host_name=MYSQL_HOST,\n",
    "    user_name=MYSQL_USR,\n",
    "    user_password=MYSQL_PWD,\n",
    "    db_name=MYSQL_DB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "item_delta = list(item_delta.itertuples(index=False, name=None))\n",
    "item_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "item_delta_string = \",\".join([\"(\" + \",\".join([str(i) for i in itm_d]) + \")\" for itm_d in item_delta])\n",
    "item_delta_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_blob(bucket_name, blob_name, destination_bucket_name, destination_blob_name):\n",
    "    \"\"\"Moves a blob from one bucket to another with a new name.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The ID of your GCS object\n",
    "    # blob_name = \"your-object-name\"\n",
    "    # The ID of the bucket to move the object to\n",
    "    # destination_bucket_name = \"destination-bucket-name\"\n",
    "    # The ID of your new GCS object (optional)\n",
    "    # destination_blob_name = \"destination-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    source_bucket = storage_client.bucket(bucket_name)\n",
    "    source_blob = source_bucket.blob(blob_name)\n",
    "    destination_bucket = storage_client.bucket(destination_bucket_name)\n",
    "\n",
    "    blob_copy = source_bucket.copy_blob(\n",
    "        source_blob, destination_bucket, destination_blob_name\n",
    "    )\n",
    "    source_bucket.delete_blob(blob_name)\n",
    "\n",
    "    print(\n",
    "        \"Blob {} in bucket {} moved to blob {} in bucket {}.\".format(\n",
    "            source_blob.name,\n",
    "            source_bucket.name,\n",
    "            blob_copy.name,\n",
    "            destination_bucket.name,\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_to_sql(df):\n",
    "    df = list(df.itertuples(index=False, name=None))\n",
    "    df_string = \",\".join([\"(\" + \",\".join([str(i) for i in df_d]) + \")\" for df_d in df])\n",
    "    return df_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_string = prepare_to_sql(item_delta)\n",
    "order_string = prepare_to_sql(order_delta)\n",
    "payment_string = prepare_to_sql(payment_delta)\n",
    "review_string = prepare_to_sql(review_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_query(db_connection,\"DESC payment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_query(db_connection,\"DESC review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_query(db_connection,\"DESC `order`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_query(db_connection,\"DESC item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_item = \"INSERT INTO item (order_id, order_item_id,\\\n",
    "                product_id, seller_id, shipping_limit_date,\\\n",
    "                price, freight_value) VALUES\"+item_string+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_payment = \"INSERT INTO payment (order_id, payment_sequential,\\\n",
    "                payment_type_id, payment_installments, payment_value)\\\n",
    "                VALUES\"+payment_string+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_review = \"INSERT INTO review (review_id, order_id,review_score,\\\n",
    "                review_comment_title,review_comment_message,\\\n",
    "                review_creation_date,review_answer_timestamp)\\\n",
    "                VALUES\"+review_string+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_order = \"INSERT INTO `order` (order_id,customer_id,order_status_id,\\\n",
    "                order_purchase_timestamp,order_approved_at,\\\n",
    "                order_delivered_carrier_date,order_delivered_customer_date,\\\n",
    "                order_estimated_delivery_date) VALUES\"+order_string+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(db_connection, insert_item)\n",
    "execute_query(db_connection, insert_order)\n",
    "execute_query(db_connection, insert_payment)\n",
    "execute_query(db_connection, insert_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in list_blobs:\n",
    "    move_blob(BUCKET_NAME,f\"/deltas_por_cargar/{blob}\",BUCKET_NAME,f\"/deltas_cargados/{blob})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb879078aa4c571fdc87a58c24b62e994516c36074b0b4e55edb62ce320b0e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
